# -*- coding: utf-8 -*-
"""LSTM-Only.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hWLAQI46qO_T3yfq7DwMdbNy9H353qtz
"""

# Google Colab Notebook for LSTM-Only Occupancy Prediction and Evaluation

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Input
from tensorflow.keras.optimizers import Adam
# New Imports for Evaluation Metrics
from sklearn.metrics import r2_score, mean_squared_error
from math import sqrt
import matplotlib.pyplot as plt

# --- Helper Function for Metrics Calculation ---
def calculate_metrics(y_true, y_pred):
    """Calculates R-squared, MSE, and RMSE."""
    # R-squared (Coefficient of Determination)
    r2 = r2_score(y_true, y_pred)

    # Mean Squared Error (MSE)
    mse = mean_squared_error(y_true, y_pred)

    # Root Mean Squared Error (RMSE)
    rmse = sqrt(mse)

    return r2, mse, rmse

# --- File Paths (Assuming files are in the local working directory) ---
# NOTE: If you are running this in Google Colab, you must manually upload these files.

# List of files to process (using only the base file names)
file_names = [
    'Miguel_Pro_cleaned.csv',
    'Gisbert_2nd_Floor_cleaned.csv',
    'American_Corner_cleaned.csv',
    'Gisbert_4th_Floor_cleaned.csv',
    'Gisbert_5th_Floor_cleaned.csv',
    'Gisbert_3rd_Floor_cleaned.csv'
]

# DataFrame to store results for all files
results_df = pd.DataFrame(columns=['File', 'R2_Score', 'MSE', 'RMSE'])

for file_name in file_names:
    # The file_name now serves as the path and the base file name
    base_file_name = file_name

    print(f"\n=======================================================")
    print(f"Processing file: {base_file_name}")
    print(f"=======================================================")

    # --- 1. Load and Preprocess Data ---
    try:
        # Read the file from the local working directory
        df = pd.read_csv(file_name)
    except FileNotFoundError:
        print(f"Error: File '{base_file_name}' not found in the local directory. Skipping.")
        continue

    df['Start_dt'] = pd.to_datetime(df['Start_dt'])
    df.set_index('Start_dt', inplace=True)
    # Correcting deprecated 'H' to 'h' for hourly resampling
    occupancy = df['Client MAC'].resample('h').nunique().rename('occupancy').reset_index()
    # Remove rows where occupancy is NaN (i.e., hours with no data)
    occupancy.dropna(inplace=True)
    # display(occupancy.head())

    # --- 2. Create Sequences for Time Series Forecasting ---
    data = occupancy['occupancy'].values.reshape(-1, 1)
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(data)

    sequence_length = 24
    X, y = [], []
    for i in range(len(scaled_data) - sequence_length):
        X.append(scaled_data[i:i+sequence_length])
        y.append(scaled_data[i+sequence_length])

    X = np.array(X)
    y = np.array(y)

    # Ensure there's enough data for splitting
    if len(X) < 2:
        print(f"Not enough data in {base_file_name} to create sequences of length {sequence_length}. Skipping.")
        continue

    # 80/20 Train/Test Split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
    print(f"Total sequences: {len(X)}. Training size: {len(X_train)}. Testing size: {len(X_test)}")

    # --- 3. Build and Train the LSTM Model ---
    # Rebuild the model for each file to ensure fresh state
    model = Sequential([
        Input(shape=(sequence_length, 1)),
        LSTM(units=50, return_sequences=True, activation='relu'),
        LSTM(units=50, activation='relu'),
        Dense(25, activation='relu'),
        Dense(1) # Output layer for single step prediction
    ])

    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')

    # model.summary() # Commenting out summary for cleaner loop output

    # Fit the model (Set verbose to 0 for less output during training)
    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=0)

    # --- 4. Evaluate the Model and Calculate Metrics ---

    # Get scaled predictions
    predictions_scaled = model.predict(X_test, verbose=0)

    # Inverse transform to get actual occupancy counts
    predictions = scaler.inverse_transform(predictions_scaled)
    y_test_actual = scaler.inverse_transform(y_test)

    # Flatten arrays for metric calculation (sklearn expects 1D arrays)
    y_true_flat = y_test_actual.flatten()
    y_pred_flat = predictions.flatten()

    # Calculate R2, MSE, RMSE
    r2, mse, rmse = calculate_metrics(y_true_flat, y_pred_flat)

    print(f"\n--- Evaluation Metrics for {base_file_name} (LSTM-Only) ---")
    print(f"R-squared (R2): {r2:.4f} (Closer to 1 is better)")
    print(f"Mean Squared Error (MSE): {mse:.2f}")
    print(f"Root Mean Squared Error (RMSE): {rmse:.2f} (In units of 'Number of Users')")

    # Store results
   
    results_df.loc[len(results_df)] = [location_name, r2, mse, rmse]

    # --- SAVE MODEL AND SCALER ---
    model_save_path = f'/opt/airflow/models/{location_name}_cnn_only.h5'
    scaler_save_path = f'/opt/airflow/models/{location_name}_cnn_only_scaler.pkl'

    try:
        model.save(model_save_path)
        print(f"Model saved to {model_save_path}")
        import pickle
        with open(scaler_save_path, 'wb') as f:
            pickle.dump(scaler, f)
        print(f"Scaler saved to {scaler_save_path}")
    except Exception as e:
        print(f"Error saving model or scaler for {location_name}: {e}")
    
    # --- 5. Visualize Results ---
    plt.figure(figsize=(15, 6))
    plt.plot(y_test_actual, label='Actual Occupancy', color='blue')
    plt.plot(predictions, label='Predicted Occupancy', color='green', linestyle='--')
    plt.title(f'LSTM Model: Actual vs. Predicted Occupancy for {base_file_name}')
    plt.xlabel('Time Step')
    plt.ylabel('Number of Users')
    plt.legend()
    plt.grid(True)
    # Save the figure to easily compare results
    # plt.savefig(f'lstm_only_{base_file_name.replace(".csv", ".png")}')
    plt.show()

print("\n\n=======================================================")
print("FINAL MODEL EVALUATION SUMMARY (LSTM-Only)")
print("=======================================================")
print(results_df.to_markdown(index=False, floatfmt=(".2f", ".4f", ".2f", ".2f")))

print("\n")
print(f"The MSE is the test loss on the inverse-transformed data, and the RMSE is the most interpretable error measure as it is in the same units as the predicted value (Number of Users). The R-squared value indicates how well the model predicts the variability in the actual data.")