name: Backend CI

on:
  push:
    branches: [main, staging]
  pull_request: {}

concurrency:
  group: backend-${{ github.ref }}
  cancel-in-progress: false

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:17-alpine
        env:
          POSTGRES_USER: wifi
          POSTGRES_PASSWORD: wifi
          POSTGRES_DB: wifi
        ports: ["5432:5432"]
        options: >-
          --health-cmd="pg_isready -U wifi -d wifi"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=10

    env:
      DEBUG: "True"
      SECRET_KEY: "test-secret"
      ALLOWED_HOSTS: "localhost,127.0.0.1"
      DB_HOST: "localhost"
      DB_PORT: "5432"
      DB_NAME: "wifi"
      DB_USER: "wifi"
      DB_PASSWORD: "wifi"
      DB_SSL_REQUIRED: "false"
      # Point loader to a temporary artifacts dir created in CI:
      MODEL_DIR: "artifacts"
      # Optional: skip expensive prediction tests unless you really need them
      SKIP_PREDICTION_TESTS: "1"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install OS deps (psql client)
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Install dependencies
        working-directory: ./backend
        run: |
          python -m pip install --upgrade pip
          pip install --no-cache-dir -r requirements.txt

      - name: Create dummy artifacts (so loader can run if invoked)
        working-directory: ./backend
        run: |
          set -e
          python - <<'PY'
          import os, pathlib, json, pickle
          base = pathlib.Path("artifacts")/"cnn"/"gisbert_3rd_floor"
          base.mkdir(parents=True, exist_ok=True)
          # Minimal preproc for CNN
          preproc = {
              "spec": {"window": 24, "feature_order": ["occupancy_scaled"], "numerical_names": ["occupancy_scaled"], "categorical_bases": []},
              "occ_scaler": None  # tests that don't call inverse_transform won't care
          }
          with open(base/"preproc.pkl","wb") as f: pickle.dump(preproc,f)
          with open(base/"meta.json","w") as f: json.dump({"model_version":"v1","horizons_min":[0],"model_family":"cnn"}, f)
          # Tiny Keras model (avoid TensorFlow import by not creating one if tests don't require it)
          # If you DO run prediction tests, build a 1-layer model here.
          PY

      - name: Wait for Postgres
        run: |
          for i in {1..30}; do
            pg_isready -h "$DB_HOST" -p "$DB_PORT" -U "$DB_USER" -d "$DB_NAME" && break
            sleep 1
          done

      - name: Run migrations
        working-directory: ./backend
        run: python manage.py migrate --noinput

      - name: Run tests
        working-directory: ./backend
        run: python manage.py test --noinput
